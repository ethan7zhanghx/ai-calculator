# AI 企业需求计算器 - 项目汇报文档

## 一、 项目背景

本项目采用 Vibe Coding 的开发模式，由产品经理（我）进行产品构思和设计，并撰写高质量的 Prompt，驱动 AI 完成项目的主要架构和代码实现。本文档旨在记录和汇报项目的构思、设计、实现与迭代的全过程。

## 二、 项目核心模块拆解

根据对项目代码结构的分析，可将项目拆分为以下几个核心模块：

1.  **核心评估引擎 (Evaluation Engine)**
    *   **简介**: 项目的核心功能，负责根据用户输入，从业务价值和技术可行性两个维度评估 AI 项目的需求。

2.  **用户认证与历史记录 (User & History)**
    *   **简介**: 负责用户注册、登录、会话管理以及保存和展示用户的历史评估记录。

3.  **管理后台 (Admin Panel)**
    *   **简介**: 为管理员提供系统管理功能，包括用户管理、评估数据查看、反馈管理和系统状态监控。

4.  **前端交互与组件 (Frontend UI)**
    *   **简介**: 整体应用的 UI/UX 设计，包括布局、主题、原子组件和业务组件的实现。

## 三、 模块一：核心评估引擎 (Evaluation Engine)

### 3.1 功能模块构思 (反向推导)

从最终的产品形态反向推导，该模块的构思起点很明确：**解决企业在 AI 立项时的“评估困境”**。

许多企业希望拥抱 AI，但决策者（如产品经理、CTO）往往面临一系列难题：如何判断一个 AI 项目的真实商业价值？如何选择合适的技术方案？如何评估硬件成本和性能瓶颈？这些问题专业性强、决策门槛高，一旦失误将导致巨大的资源浪费。

因此，本模块的核心构思是**打造一个“AI 项目专家顾问”**，它能：
*   **降低决策门槛**：用户无需成为 AI 专家，只需输入项目的基本构想，就能获得专业的评估报告。
*   **提供双维视角**：同时从“商业价值”和“技术可行性”两个关键维度进行分析，确保决策的全面性。
*   **量化与定性结合**：不仅给出定性的分析，还提供量化的分数，使评估结果更直观、更易于比较。
*   **提供可执行建议**：最终目标不是给出“yes/no”的答案，而是提供具体的风险提示和优化建议，帮助用户规避陷阱、优化方案。

### 3.2 Prompt 设计与 AI 协作

*（**请您在此处填写**：可以贴出您当时用于驱动 AI 生成 `business-evaluator.ts` 或 `technical-evaluator.ts` 的核心 Prompt。我们可以看到，最终代码里的 Prompt 已经非常完善，记录最初的 Prompt 将能很好地展示迭代过程。）*

### 3.3 内部设计细节

这部分由我基于对代码的分析来阐述。核心评估引擎是整个应用的大脑，其设计精妙之处在于它并非单一的 AI 调用，而是**一个结合了确定性计算、专家知识库和大型语言模型（LLM）定性分析的混合式智能系统**。

#### 1. 架构概览：双核驱动

评估引擎由两个核心模块构成，分别负责从不同维度进行分析：

*   **商业价值评估器 (`business-evaluator.ts`)**: 完全由 LLM 驱动，扮演“AI 商业顾问”角色，进行定性分析。
*   **技术方案评估器 (`technical-evaluator.ts`)**: 采用“确定性计算 + LLM”的混合模式，扮演“AI 技术架构师”角色，进行定量与定性结合的分析。

这种设计体现了“让专业的人做专业的事”的原则：商业价值这种开放性、策略性强的问题，交给擅长理解和推理的 LLM；而技术可行性中包含大量硬指标，则通过代码精确计算，避免 AI 的“幻觉”和模糊性。

#### 2. 关键实现：Prompt 即代码 (Prompt as Code)

整个模块最核心的实现，完美诠释了 Vibe Coding 的思想——通过高质量的 Prompt 将复杂的业务逻辑和评估标准“注入”给 AI。

*   **角色设定 (Role-Play)**: 通过 `SYSTEM_PROMPT`，我们明确地将 AI 的角色设定为“资深 AI 商业顾问”或“资深 AI 技术架构师”，这使得 AI 的回答风格和思考角度都向专家靠拢。
*   **Few-Shot 学习**: 我们没有让 AI 从零开始思考，而是为其提供了 3-5 个精心设计的“案例 (Few-Shot Examples)”。这些案例覆盖了从“致命错误”到“优秀方案”的各种场景，相当于为 AI 提供了高质量的“教科书”，教会了它评估的基准和模式。
*   **结构化输出 (JSON Schema)**: 通过 `response_format: { type: "json_object" }` 指令和详尽的 TypeScript 接口定义，我们强制 AI 的输出必须是严格的 JSON 格式。这极大地简化了后端处理和前端展示的逻辑，保证了系统的稳定性和可预测性。

#### 3. 混合评估模式：硬指标计算与软实力分析

技术评估模块的设计尤为出色，它分两步走：

*   **第一步：确定性计算 (`resource-calculator.ts`)**
    *   **内置知识库**: 代码中硬编码了主流 GPU 的显存 (`hardwareSpecs`) 和大模型的参数量 (`MODEL_KNOWLEDGE`)。
    *   **公式化评估**: 基于业界公认的经验公式，精确计算在 FP16 精度下，不同任务（推理、微调、预训练）所需的显存。例如，全参数微调的显存需求被估算为 `参数量 * 2 * 4`。
    *   **性能预估**: 不仅计算“能否运行”，还估算了在特定硬件上能达到的性能（TPS/QPS），并与用户需求进行对比。
    *   **提供具体建议**: 根据计算结果，系统会自动生成如“建议使用 LoRA 微调”或“建议使用 INT8 量化”等具体、可执行的建议。

*   **第二步：LLM 增强分析**
    *   前一步计算出的“硬件资源可行性得分”会被作为“先验知识”注入到给 LLM 的 Prompt 中。
    *   LLM 在此基础上，专注于评估更“软”的维度，如模型与业务的匹配度、微调的必要性、实施路径的规划等，并给出综合性的分析和总分。

#### 4. 数据流

1.  用户在前端页面提交业务场景、模型、硬件等信息。
2.  请求到达后端 API (`/api/evaluate/route.ts`)。
3.  后端并行调用 `evaluateBusinessValue` 和 `evaluateTechnicalSolution`。
4.  在 `evaluateTechnicalSolution` 内部，首先调用 `calculateResourceFeasibility` 进行硬件资源的确定性计算。
5.  然后，两个评估器各自构建包含角色设定、Few-Shot 案例和用户需求的复杂 Prompt。
6.  通过 `fetchWithRetry`（一个增加了重试和超时逻辑的封装）调用百度千帆 ERNIE-4.5 API。
7.  API 返回严格的 JSON 格式结果。
8.  后端将两份评估结果整合，返回给前端进行可视化展示。

### 3.4 迭代与优化 (反向推导)

从代码的实现细节，我们可以清晰地看到一条从简单到复杂的迭代优化路径，这充分体现了在与 AI 协作过程中的深度思考和持续打磨。

*   **第一阶段：从单一 AI 到“双核”专家**
    *   **初期设想**: 很可能最初只是一个简单的 Prompt，让 AI 对整个项目进行一次笼统的评估。
    *   **迭代**: 很快就会发现，单个 AI 难以兼顾商业和技术两个差异巨大的领域。因此，方案演进为创建两个独立的评估器（`business-evaluator` 和 `technical-evaluator`），并为它们分别设定了“商业顾问”和“技术架构师”的专家角色，实现了评估的专业化和深度化。

*   **第二阶段：从模糊感到精确化——引入确定性计算**
    *   **遇到的问题**: 在技术评估中，AI 对于显存、性能等“硬指标”的评估是模糊且不可靠的，它可能会“感知”一个大概的结果，但无法进行精确计算，甚至会产生“幻觉”。
    *   **“啊哈”时刻的迭代**: 认识到 AI 的能力边界后，一个关键的迭代发生了——将确定性问题从 AI 的任务中剥离。我们创建了 `resource-calculator.ts`，用精准的数学公式来计算显存占用和性能（TPS）。这部分代码不依赖 AI，保证了结果的 100% 可靠。
    *   **形成混合模式**: 计算出的硬指标分数，再作为“不可挑战的事实”注入到 Prompt 中，让 AI 在此基础上进行更高层次的“软实力”分析（如模型选型匹配度）。这形成了“确定性计算+AI定性分析”的高级混合模式，是整个模块设计的点睛之笔。

*   **第三阶段：从“听话”到“懂事”——打磨 Few-Shot 案例**
    *   **遇到的问题**: 即使有了角色设定，AI 的输出质量和格式依然不稳定。
    *   **迭代**: 通过引入 `FEW_SHOT_EXAMPLES`，我们为 AI 提供了高质量的“学习范本”。这些案例的演进可能经历了：
        1.  **初期**: 只有一两个简单的“好/坏”案例。
        2.  **中期**: 增加了更复杂的场景，如“技术选型过度”（杀鸡用牛刀）、“RAG 方案”等，教会 AI 进行更细致的利弊权衡。
        3.  **成熟期**: 补充了如“医疗”、“金融”等高风险领域的案例，让 AI 学会了评估风险和合规性，并给出分阶段的实施路径。

*   **第四阶段：从能用到好用——提升系统健壮性**
    *   **遇到的问题**: 在实际调用千帆 API 的过程中，一定遇到了网络波动或 API 响应缓慢导致请求失败的问题。
    *   **迭代**: 为了解决这个问题，我们引入了 `fetchWithRetry` 机制。代码中设置了高达 6 次的重试和 180 秒的超时时间，这表明我们通过实践找到了一个能显著提升服务稳定性的策略，确保了即使用户网络或上游服务出现暂时性问题，评估任务也能大概率成功完成。

---

## 四、 模块二：用户认证与历史记录 (User & History)

### 4.1 功能模块构思 (反向推导)

任何一个严肃的应用程序都需要一个安全、可靠的用户系统。本模块的构思旨在解决三个核心问题：

1.  **用户身份识别与安全**: 如何确保只有注册用户才能使用服务，并保护他们的个人信息（特别是密码）不被泄露？
2.  **个性化体验**: 如何保存每个用户的评估历史，让他们可以随时回顾、比较和分析自己的决策过程？
3.  **系统扩展性**: 如何设计一个既能满足当前需求，又能为未来可能的管理员角色、权限管理等功能预留空间的认证系统？

基于以上思考，本模块的核心构思是构建一个基于行业标准实践的、安全且可扩展的认证与数据持久化层。

### 4.2 内部设计细节

#### 1. 认证流程：JWT 无状态认证

本模块采用了现代 Web 开发中主流的 **JWT (JSON Web Token)** 认证方案。

1.  **注册/登录**: 用户通过邮箱或手机号及密码进行注册或登录。
2.  **密码加密**: 在任何时候，用户的原始密码都不会被存储。系统在接收到密码后，会立即通过 `bcrypt` 算法进行**哈希加密**，只将加密后的哈希值存入数据库。
3.  **Token 生成**: 验证通过后，服务器会生成一个包含用户 ID 等非敏感信息的 JWT，并将其返回给客户端。
4.  **无状态通信**: 在后续的所有请求中，客户端都会在请求头中携带这个 JWT。服务器只需验证此 Token 的有效性，即可确认用户身份，无需在自身存储任何 Session 信息。这种“无状态”的设计使得应用非常容易进行水平扩展。

#### 2. 数据模型与持久化：Prisma 与 灵活的 JSON 存储

我们使用 [Prisma](https://www.prisma.io/) 作为 ORM (对象关系映射) 工具来与数据库交互，它提供了类型安全的数据操作。数据模型的设计体现了清晰的关系和对未来变化的适应性。

*   **核心关系**: `User` (用户) 与 `Evaluation` (评估记录) 之间是标准的一对多关系。通过 `onDelete: Cascade` 约束，我们确保了当用户注销账户时，其个人数据会被彻底清除，符合数据隐私的最佳实践。
*   **关键设计——JSON 存储**: 这是一个非常重要的设计权衡。我们将评估结果（一个复杂的、可能经常变化的对象）作为一个整体的 **JSON 字符串**存储在数据库的单个字段中。
    *   **优点**: 极大地提高了迭代灵活性。当我们优化 Prompt 导致 AI 输出的评估维度增加或改变时，我们**无需修改数据库结构**，避免了繁琐的数据迁移工作。
    *   **缺点**: 无法直接在数据库层面针对结果内的某个具体字段（例如 `technicalFeasibility.score`）进行高效查询。
    *   **结论**: 在当前阶段，迭代速度和灵活性远比复杂查询更重要，因此这是一个完全正确且明智的工程决策。

### 4.3 迭代与优化 (反向推导)

*   **第一阶段：基础实现**: 最初的版本可能只支持邮箱+密码注册，并且将所有评估输入和输出的字段都在数据库中创建了对应的列。
*   **迭代一：引入手机号注册**: 为了提升用户体验和覆盖更多用户群体，增加了对手机号注册和登录的支持，并处理了邮箱/手机号二选一的逻辑。
*   **迭代二：从“硬”到“软”的数据库设计**: 当开发“核心评估引擎”时，我们一定很快发现评估结果的结构在不断变化。每次 Prompt 的微调都可能导致数据库结构的变更，这极大地拖慢了开发速度。因此，一个关键的优化发生了：将易变的评估结果从“硬”的列结构改为“软”的 JSON 字段存储，从而解放了生产力。
*   **迭代三：为未来做准备**: 在 `User` 模型中增加了 `role` 字段。虽然在当前的核心功能中可能还未使用到，但它为后续开发“管理后台”、实现角色权限控制（RBAC）等高级功能预先埋下了伏笔，体现了设计的长远眼光。
