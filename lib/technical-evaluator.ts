/**
 * 技术方案评估器
 * 使用百度千帆ERNIE-4.5进行深度评估，基于Few-Shot Learning
 */

import type { EvaluationRequest } from "./types"
import { formatModelInfo } from "./model-knowledge-base"
import { fetchWithRetry } from "./api-retry"

export interface TechnicalEvaluationResult {
  score: number // 0-100，用于前端评分条展示

  // 核心评估结论
  summary: string

  // 详细的维度分析
  dimensions: {
    // 1. 模型与业务匹配度
    modelTaskAlignment: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      status: "matched" | "mismatched" | "partial"
      analysis: string
    }

    // 2. 大模型必要性
    llmNecessity: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      status: "necessary" | "unnecessary" | "debatable"
      analysis: string
      alternatives?: string
    }

    // 3. 微调评估
    fineTuning: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      necessary: boolean
      dataAdequacy: "sufficient" | "marginal" | "insufficient"
      analysis: string
    }

    // 4. 业务可行性与实施路径
    implementationRoadmap: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      feasible: boolean
      analysis: string
      phases: {
        shortTerm?: string[] // 1-2个月可落地
        midTerm?: string[] // 3-6个月可落地
        notRecommended?: string[] // 不建议做
      }
    }

    // 5. 性能需求评估
    performanceRequirements: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      reasonable: boolean
      analysis: string
    }

    // 6. 成本效益
    costEfficiency: {
      score: number // 0-100
      scoreRationale: string // 对该评分的简要说明
      level: "reasonable" | "high" | "excessive"
      analysis: string
    }

    // 7. 领域特殊考虑
    domainConsiderations?: {
      score?: number // 0-100, 可选
      scoreRationale?: string // 对该评分的简要说明
      applicable: boolean
      analysis: string
    }
  }

  // 关键问题（阻断性）
  criticalIssues: string[]

  // 警告问题
  warnings: string[]

  // 实施建议
  recommendations: string[]
}

/**
 * 使用ERNIE-4.5评估技术方案
 */
export async function evaluateTechnicalSolution(
  req: EvaluationRequest
): Promise<TechnicalEvaluationResult> {
  const apiKey = process.env.QIANFAN_API_KEY

  if (!apiKey) {
    throw new Error("QIANFAN_API_KEY 环境变量未设置")
  }

  try {
    const prompt = buildEvaluationPrompt(req)

    // 使用带重试的 fetch,最多重试5次,单次超时45秒
    const response = await fetchWithRetry(
      "https://qianfan.baidubce.com/v2/chat/completions",
      {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Authorization": `Bearer ${apiKey}`,
          "X-Appbuilder-Authorization": apiKey, // IAM鉴权必需的header
        },
        body: JSON.stringify({
          model: "ernie-4.5-turbo-128k",
          messages: [
            {
              role: "system",
              content: SYSTEM_PROMPT,
            },
            {
              role: "user",
              content: prompt,
            },
          ],
          response_format: {
            type: "json_object",
          },
          temperature: 0.3, // 低温度保证一致性
        }),
      },
      {
        maxRetries: 5,
        timeout: 120000, // 120秒超时
        initialDelay: 2000,
        onRetry: (attempt, error) => {
          console.log(`技术评估API重试 (${attempt}/5):`, error.message)
        },
      }
    )

    const data = await response.json()

    // 检查千帆API的错误响应
    if (data.error_code || data.error_msg) {
      throw new Error(`千帆API错误: ${data.error_msg || data.error_code}`)
    }

    if (!data.choices?.[0]?.message?.content) {
      throw new Error("千帆API返回数据格式异常")
    }

    const content = data.choices[0].message.content

    const result = JSON.parse(content) as TechnicalEvaluationResult
    return result
  } catch (error) {
    console.error("技术评估失败:", error)

    // 如果是JSON解析错误,提供更详细的信息
    if (error instanceof SyntaxError) {
      throw new Error("AI返回的JSON格式无效,请重试")
    }

    // 如果是网络或API错误,保持原错误信息
    if (error instanceof Error) {
      throw error
    }

    throw new Error("技术方案评估服务暂时不可用，请稍后重试")
  }
}

/**
 * 系统提示词（固定，会被千帆缓存）
 */
const SYSTEM_PROMPT = `你是一位资深AI技术架构师，擅长评估企业AI项目的技术方案合理性。

## 评估维度与权重

你需要从以下7个维度全面评估技术方案，每个维度单独打分(0-100分)：

1. **模型类型与业务匹配度 (20%)** - 模型能力是否匹配业务需求
2. **大模型必要性 (15%)** - 是否真的需要大模型，还是小模型/传统方案就能解决
3. **微调必要性和数据充分性 (20%)** - 是否需要微调，数据量和质量是否足够
4. **业务可行性与实施路径 (20%)** - 业务需求是否在技术边界内，如何分阶段实施
5. **性能需求合理性 (10%)** - QPS和并发数配比是否合理，是否符合业务场景
6. **成本效益 (10%)** - 模型选型的成本是否合理（仅考虑模型API成本，不含硬件）
7. **领域特殊性 (5%)** - 是否有医疗/金融/法律等特殊领域的考虑

**总分计算**：按上述权重加权平均得出

## 评估原则

1. **客观性**：实事求是，发现问题要明确指出，不回避矛盾
2. **连贯性**：每个维度的analysis字段用2-4句连贯的话进行深入分析（100-200字），而非简单罗列要点
3. **分层性**：区分致命问题(criticalIssues)和警告(warnings)，不要混在一起
4. **可操作性**：建议要具体可执行，不要只说"建议优化"这种空话
5. **深度思考**：要解释"为什么"，不仅说"是什么"，提供有价值的洞察

## 评分标准

### 总分范围 (0-100)
- **90-100分**：方案非常优秀，技术选型精准，各方面考虑周全
- **80-89分**：整体合理，有小的改进空间，但不影响实施
- **60-79分**：有明显问题但整体可行，需要优化后才能达到理想效果
- **40-59分**：严重问题，需要重大调整才能继续
- **0-39分**：致命错误，方案根本无法实现（如视觉任务选文本模型）

### 各维度评分标准 (0-100)
- **90-100分**：该维度表现优秀，无明显改进空间
- **70-89分**：该维度合理，有小的优化建议
- **50-69分**：该维度存在明显问题，需要调整
- **30-49分**：该维度有严重问题，需要重大改变
- **0-29分**：该维度完全不合理，致命缺陷

## 输出要求

1. **总分(score)**：按权重加权平均计算的总分(0-100)
2. **summary**：用2-3句话总结核心评估结论和主要问题/亮点（100-150字）
3. **每个维度必须包含**：
   - **score**: 该维度的评分(0-100)
   - **scoreRationale**: 对该评分的简要说明(1-2句话)，解释为什么给出这个分数
   - **status/level**: 状态标识
   - **analysis**: 用段落式叙述进行深入分析（2-4句话，100-200字），解释"为什么"而非仅说"是什么"
4. **implementationRoadmap**：
   - 如果场景复杂，必须给出分阶段实施路径（shortTerm、midTerm、notRecommended）
   - shortTerm：1-2个月可落地的功能
   - midTerm：3-6个月可落地的功能
   - notRecommended：高风险不建议做的部分
5. **criticalIssues**：只放阻断性问题，导致方案无法实施的问题
6. **warnings**：需要注意但不阻断的问题
7. **recommendations**：3-5条具体可执行的建议，每条说明"做什么"和"为什么"

## 分析深度要求

- **段落式分析**：不要写短句列表，要写完整段落
- **逻辑推理**：要有逻辑推理过程，不只是描述现象
- **实际价值**：要提供有价值的洞察，而非空洞的套话
- **平衡视角**：既要看到优点，也要指出风险`

/**
 * 构建评估Prompt（包含Few-Shot案例和当前输入）
 */
function buildEvaluationPrompt(req: EvaluationRequest): string {
  const dataTypesStr = req.businessData.dataTypes
    .map((t) => {
      const map: Record<string, string> = {
        text: "文本",
        image: "图片",
        qa_pair: "QA对话",
        video: "视频",
        audio: "音频",
      }
      return map[t] || t
    })
    .join("、")

  const qualityStr = req.businessData.quality === "high" ? "已治理" : "未治理"

  // 获取模型信息
  const modelInfo = formatModelInfo(req.model)

  return `# Few-Shot 评估案例

## 案例1：致命错误 - 视觉任务选择文本模型

**输入：**
- 业务场景：电商产品图片自动生成描述，用于商品详情页
- 模型：GPT-3.5（纯文本，不支持视觉）
- 数据：8000张产品图片 + 人工标注的描述，已治理
- 性能需求：QPS 20，并发：50
- 硬件配置：A100 80GB × 2张

**输出：**
\`\`\`json
{
  "score": 12,
  "summary": "技术方案存在根本性致命错误，完全无法实施。业务核心需求是理解产品图片内容并生成描述文字，这是典型的多模态任务，必须使用具备视觉理解能力的多模态大模型。然而GPT-3.5是纯文本语言模型，完全不支持图像输入，无法接收和处理任何图片数据，这使得整个方案从技术基础上就站不住脚。这不是参数调优或Prompt工程能够解决的问题，而是模型类型选择上的根本性错误，类似于试图用收音机来拍照。虽然数据准备（8000张图片，已治理）和性能规划（QPS 20，并发50）都较为合理，但在模型选型这个前提错误的情况下，其他所有合理性都失去了意义。必须立即更换为支持视觉输入的多模态模型（如GPT-4 Vision、Claude 3 Sonnet/Opus、Gemini Pro Vision等）才有继续讨论的基础。",
  "dimensions": {
    "modelTaskAlignment": {
      "score": 0,
      "scoreRationale": "模型类型与任务需求完全不匹配，纯文本模型无法处理图像输入，导致方案从根本上无法实现。",
      "status": "mismatched",
      "analysis": "业务需求的核心是从产品图片中提取视觉信息（颜色、材质、款式、细节等），并将其转化为自然流畅的商品描述文字，这是典型的视觉-语言跨模态理解与生成任务。GPT-3.5作为纯文本大语言模型，其输入层只能接受文本token，完全不具备图像编码器和视觉理解模块，无法处理任何形式的图片输入。这种不匹配是架构层面的根本性缺陷，不是通过Few-Shot、Chain-of-Thought或任何Prompt工程技巧能够弥补的。这个错误的严重性相当于企图用只有CPU的服务器来训练深度学习模型，或者用纯音频设备来录制视频，是对AI模型能力边界的基本误判。选择GPT-3.5处理图像描述任务，就像拿着锤子去拧螺丝，工具与任务之间存在本质的不兼容。"
    },
    "llmNecessity": {
      "score": 90,
      "scoreRationale": "业务需求需要复杂的视觉理解和自然语言生成能力，这正是多模态大模型的优势所在，传统方案难以胜任。",
      "status": "necessary",
      "analysis": "从业务需求分析来看，使用大语言模型的方向判断是完全正确的。电商产品图片描述生成需要三个核心能力：第一，准确识别图片中的视觉元素（物品类别、颜色、材质、风格等）；第二，理解这些视觉元素的语义和特征；第三，将视觉理解转化为符合电商场景的自然语言描述，包含营销话术、规格参数、使用场景等。传统计算机视觉方案（如目标检测+属性识别）只能输出离散的标签和检测框，无法生成流畅连贯的段落式描述。规则模板方法虽然可以填充文字，但生成内容机械生硬，缺乏灵活性和自然度。只有多模态大语言模型才能同时具备视觉理解、语义推理和自然语言生成三重能力，实现从图片到描述的端到端转换。因此，使用大模型的技术路线选择是正确的，唯一的问题是选错了具体的模型类型——应该选择多模态模型而非纯文本模型。"
    },
    "fineTuning": {
      "score": 75,
      "scoreRationale": "数据准备和微调思路合理，但因模型选型错误，这些准备工作无法发挥实际作用，因此分数有所保留。",
      "necessary": true,
      "dataAdequacy": "sufficient",
      "analysis": "数据准备和微调规划展现出了合理的技术思路。电商产品描述具有明显的行业特征和风格要求：特定的术语体系（如服装行业的'版型''面料'，3C行业的'性能参数'），统一的品牌话术和营销风格，以及符合目标用户群体阅读习惯的表达方式。这些领域特定知识很难通过通用模型的预训练数据充分学习，必须通过微调来让模型深度适配业务场景。8000张产品图片配对人工标注的高质量描述，数据规模对于多模态模型的微调来说是充足的（业界经验显示5000-10000对图文数据即可实现有效微调），且数据已经过治理，质量有保障。如果按照正确的技术路线（选择多模态模型），这套数据完全可以支撑LoRA或全量微调，学习品牌特定的描述风格和术语习惯。但在当前错误选择GPT-3.5的前提下，这些数据准备工作都无法发挥作用，因为模型根本无法接收图片输入进行训练。"
    },
    "implementationRoadmap": {
      "score": 0,
      "scoreRationale": "由于模型无法处理输入数据，当前方案完全不具备可行性，任何实施计划都没有意义。",
      "feasible": false,
      "analysis": "当前技术方案在最基础的模型能力层面就存在不可逾越的障碍，完全不具备实施的可行性。任何实施路径的讨论都必须建立在模型能够处理输入数据的前提之上，而GPT-3.5无法接收图片输入这一事实，使得所有后续的开发、测试、部署计划都成为空中楼阁。这不是'需要优化'或'存在风险'的问题，而是'根本无法运行'的致命缺陷。在技术选型纠正之前，任何关于分阶段实施、MVP验证、灰度发布的讨论都没有意义。项目必须立即停止当前路线，回到技术选型阶段重新开始。尝试用变通方案（如先用OCR识别图片中的文字，再用GPT-3.5处理）不仅增加复杂度和成本，还会严重损害最终效果，因为OCR只能提取文字信息，无法捕捉颜色、材质、款式等视觉特征，而这些恰恰是产品描述的核心内容。"
      "phases": {
        "notRecommended": [
          "禁止继续使用GPT-3.5推进项目，该模型从技术原理上就无法完成图片理解任务",
          "不要尝试通过'OCR提取文字+GPT-3.5描述'的变通方案，这会丢失核心的视觉信息（颜色、材质、款式等）",
          "不要投入任何开发资源在当前技术架构上，所有工作都将因模型能力缺失而白费",
          "不要试图通过Prompt工程或外部API拼接来弥补模型能力缺陷，这种补丁式方案不可能达到生产级别的稳定性和效果"
        ]
      }
    },
    "performanceRequirements": {
      "score": 80,
      "scoreRationale": "性能指标规划合理，符合业务场景需求，但这些指标是基于错误的技术前提，因此分数有所保留。",
      "reasonable": true,
      "analysis": "性能需求的规划展现出了对业务场景的合理理解。QPS 20（每秒20次请求）对应每天约172万次商品描述生成，适合中型电商平台的商品上新和描述更新需求。并发数50是QPS的2.5倍，这个比例符合多模态模型推理的典型特征：图像编码和跨模态理解的计算复杂度较高，单次推理耗时通常在2-4秒，并发数需要相应提高以维持目标QPS。如果使用GPT-4 Vision或Claude 3等云端API，QPS 20的负载完全可以通过并发调用实现；如果选择本地部署开源多模态模型（如LLaVA、CogVLM），2张A100 80GB配置也能够支撑这个性能要求（考虑batch推理和模型量化优化）。然而需要指出的是，虽然性能规划合理，但GPT-3.5本身无法处理图像输入，因此这些性能指标都是基于错误的技术前提，实际部署时需要根据最终选定的多模态模型重新评估和调整。"
    },
    "costEfficiency": {
      "score": 40,
      "scoreRationale": "选择了无法完成任务的模型，导致所有成本投入都将被浪费，是典型的'省小钱吃大亏'。",
      "level": "high",
      "analysis": "成本评估方面存在严重的规划失误。虽然选择GPT-3.5看似是出于成本考虑（其API价格远低于GPT-4 Vision），但这是典型的'省小钱吃大亏'的错误决策。由于GPT-3.5完全无法处理图像任务，这个'低成本方案'实际上不会产生任何有效产出，相当于投入的每一分钱都被浪费。正确的成本规划应该在'能够完成任务的模型'中进行比较，而不是简单选择最便宜的选项。如果使用云端多模态模型API（如GPT-4 Vision、Claude 3 Sonnet、Gemini Pro Vision），按QPS 20计算，月成本约在数千到万元级别，看似高昂，但考虑到能够替代大量人工撰写商品描述的劳动力成本（一个文案编辑月薪8000-15000元，每天最多完成50-100个商品描述），自动化方案的ROI仍然是可观的。如果预算有限，可以考虑开源多模态模型（LLaVA-1.5、Qwen-VL等）的本地部署方案，虽然初期需要投入GPU资源和部署成本，但边际成本会大幅降低。关键是要基于'技术可行'的前提进行成本优化，而不是盲目追求低价。"
    }
  },
  "criticalIssues": [
    "模型类型根本性错误：GPT-3.5是纯文本模型，完全不支持图像输入，无法处理产品图片",
    "技术方案从基础架构层面就无法实施，不是优化或调整的问题，而是必须推翻重来",
    "所有后续规划（数据准备、性能优化、部署方案）都建立在错误的技术前提上，当前路线下没有任何可行性"
  ],
  "warnings": [],
  "recommendations": [
    "立即停止当前技术路线，重新进行模型选型。必须选择支持视觉输入的多模态大模型，如GPT-4 Turbo with Vision、Claude 3 Sonnet/Opus、Gemini Pro Vision、Qwen-VL-Max等",
    "云端API vs 本地部署的权衡：如果追求快速上线和稳定性，建议使用Claude 3 Sonnet API（性价比高且效果好）；如果有长期大规模需求且预算充足，可考虑开源模型（LLaVA-1.5、CogVLM、Qwen-VL）本地部署，2张A100 80GB足以支撑",
    "充分利用已准备的8000张图文对数据进行模型微调，学习电商产品描述的专业术语、品牌话术和目标用户的阅读偏好，这是形成差异化竞争力的关键",
    "建立人工审核和质量监控机制：AI生成的描述在上线前应进行抽样人工审核，检查准确性、品牌调性、营销效果，并持续收集反馈用于模型迭代",
    "分阶段实施策略：短期（1-2月）先从标准品类（服装、家电等品类特征明确的商品）切入，建立基线效果和用户信任；中期（3-6月）扩展到更多品类，优化长尾场景；逐步提高AI自动化比例，降低人工介入",
    "成本优化建议：初期可采用'AI初稿+人工润色'的混合模式，降低质量风险的同时逐步提升用户对AI生成内容的接受度"
  ]
}
\`\`\`

---

## 案例2：技术选型过度 - OCR场景误用大模型

**输入：**
- 业务场景：扫描合同文档进行文字识别和信息提取
- 模型：GPT-4（1.7T参数，多模态，128K上下文）
- 数据：5000份扫描合同，已标注关键信息字段，已治理
- QPS需求：10，并发：20

**输出：**
\`\`\`json
{
  "score": 48,
"summary": "技术方案存在严重的成本效益问题：业务需求分为OCR文字识别和信息提取两部分，而当前方案用GPT-4同时处理两项任务是典型的技术选型过度。OCR是成熟的计算机视觉任务，应该使用专业OCR工具而非大语言模型，直接用GPT-4做OCR的成本是专业方案的100倍以上，且准确率未必更高。正确的做法是采用两阶段方案：专业OCR工具完成文字识别+小模型（如GPT-3.5微调）完成信息提取，成本可降低90%且效果更好。",
  "dimensions": {
    "modelTaskAlignment": {
      "score": 55,
      "scoreRationale": "模型能力远超任务所需，用GPT-4做OCR是典型的高射炮打蚊子，造成严重资源浪费。",
      "status": "partial",
      "analysis": "业务任务分为两个截然不同的部分：OCR文字识别和信息提取。GPT-4的多模态能力可以处理图像输入并提取信息，但这是用高射炮打蚊子——OCR是高度成熟的计算机视觉任务，有PaddleOCR、Tesseract等专门优化的解决方案，准确率高、速度快、成本低。GPT-4的价值应该体现在信息提取环节，而不是浪费在基础的文字识别上。这种选型类似于用超级计算机来做简单的算术运算，虽然能完成任务，但严重浪费资源。"
    },
    "llmNecessity": {
      "score": 65,
      "scoreRationale": "OCR环节完全不需要大模型，信息提取环节也未必需要GPT-4级别的模型，存在过度设计的风险。",
      "status": "debatable",
      "analysis": "大模型对于整个任务流程来说并非完全不必要，但需要明确区分哪个环节真正需要大模型。OCR文字识别环节完全不需要大模型，这是传统CV技术的成熟应用场景。信息提取环节确实需要语言理解能力，但也不一定要用GPT-4这样的超大模型，GPT-3.5或者其他中等规模模型微调后完全可以胜任合同字段提取任务。只有在合同内容极其复杂、需要深度推理和理解的场景下，才需要考虑GPT-4级别的模型。",
      "alternatives": "OCR部分使用PaddleOCR、Tesseract或云服务OCR API（如百度OCR、阿里OCR），成本降低95%以上且准确率更高。信息提取部分使用GPT-3.5或Claude 3 Haiku微调，成本是GPT-4的1/10，效果不会有明显差异。"
    },
    "fineTuning": {
      "score": 80,
      "scoreRationale": "微调思路和数据准备合理，但应应用于更具性价比的小模型，而非直接在GPT-4上操作。",
      "necessary": true,
      "dataAdequacy": "sufficient",
      "analysis": "合同信息提取是典型的领域特定任务，涉及大量法律术语、特定字段格式和业务逻辑，必须通过微调让模型学习这些领域知识。5000份已标注的扫描合同数据量充足，可以覆盖常见的合同类型和字段变化。数据已经过治理，说明质量有保障。这部分规划是合理的，但前提是要先用正确的技术架构——OCR+微调后的小模型，而不是全部交给GPT-4。"
    },
    "implementationRoadmap": {
      "score": 70,
      "scoreRationale": "方案可行但路径需要优化，改为两阶段架构（OCR+小模型）会更高效、更经济。",
      "feasible": true,
      "analysis": "技术方案整体可行，但实施路径需要调整。正确的做法是采用两阶段流水线架构：第一阶段用专业OCR工具（如PaddleOCR或云服务）完成文字识别，第二阶段用微调后的语言模型完成信息提取。这种架构清晰、成本可控，且每个环节都使用最适合的技术。1-2周可以完成OCR集成和测试，2-4周可以完成信息提取模型的微调和部署，整体实施周期合理。",
      "phases": {
        "shortTerm": [
          "第一阶段(1-2周)：集成专业OCR方案（PaddleOCR或云服务）完成文字识别，建立基线准确率",
          "第二阶段(2-4周)：使用GPT-3.5或Claude 3 Haiku微调完成信息提取，用5000份标注数据训练"
        ],
        "midTerm": [
          "第三阶段(1-2个月)：根据提取准确率评估是否需要升级到更大模型（如GPT-4），但仅用于信息提取环节"
        ],
        "notRecommended": [
          "不要用GPT-4直接处理OCR任务，成本极高且无必要",
          "不要跳过微调直接用通用模型，合同领域术语太专业"
        ]
      }
    },
    "performanceRequirements": {
      "score": 85,
      "scoreRationale": "性能指标合理，但当前方案（GPT-4）难以满足，而推荐的两阶段方案则可以轻松实现。",
      "reasonable": true,
      "analysis": "QPS 10、并发20对于合同处理场景来说是非常合理的低负载需求，符合B端文档处理系统的典型特征。并发数是QPS的2倍，考虑到文档处理的时间（OCR+信息提取可能需要2-3秒），这个比例是合适的。这种负载下，专业OCR工具可以轻松应对，微调后的小模型也完全可以满足，完全不需要GPT-4的强大推理能力。"
    },
    "costEfficiency": {
      "score": 15,
      "scoreRationale": "成本效益极差，使用GPT-4处理OCR任务的成本是专业方案的数十倍甚至上百倍，完全不合理。",
      "level": "excessive",
      "analysis": "这是本方案最严重的问题：成本效益极差。直接用GPT-4处理OCR和信息提取，每次调用成本是专业方案的数十倍甚至上百倍。OCR云服务（如百度OCR）每千次调用成本仅几元，而GPT-4 Vision每千次调用成本高达数十美元。即使是信息提取环节，GPT-3.5微调后的成本也远低于GPT-4。按照QPS 10计算，每天8.64万次调用，采用GPT-4方案月成本可能高达数万元，而两阶段方案（专业OCR + 微调小模型）月成本可能仅需数千元，成本可降低90%以上，ROI差距巨大。"
    },
    "domainConsiderations": {
      "score": 75,
      "scoreRationale": "方案考虑到了法律领域的特殊性，但可以通过更优的架构来更好地解决数据隐私和合规问题。",
      "applicable": true,
      "analysis": "合同处理属于法律文档领域，对准确性和合规性要求极高。AI提取的关键字段（如合同金额、生效日期、主体信息）必须经过人工校验，不能直接用于业务决策。此外，法律文档可能涉及敏感信息，如果使用云端API（如GPT-4）需要考虑数据隐私和合规问题。建议采用本地部署的开源模型或私有化部署的方案，并配置完善的人工审核流程，确保关键信息的准确性和数据安全性。"
    }
  },
  "criticalIssues": [
    "成本效益严重不合理：使用GPT-4做OCR文字识别，成本是专业方案的100倍以上"
  ],
  "warnings": [
    "法律文档处理需要高准确率，AI提取后必须配置人工审核关键字段",
    "使用云端API可能涉及数据隐私和合规问题，需评估风险"
  ],
  "recommendations": [
    "立即调整技术架构：采用两阶段方案（专业OCR工具 + 微调小模型），而非全部使用GPT-4",
    "OCR环节使用PaddleOCR（开源免费）或云服务OCR API（如百度OCR、阿里OCR），成本低且准确率高",
    "信息提取环节使用GPT-3.5或Claude 3 Haiku微调，用5000份标注数据学习合同领域术语和字段格式",
    "配置人工审核流程，对AI提取的关键字段（如金额、日期、主体、条款）进行100%人工校验",
    "评估数据隐私需求，如果合同涉及敏感信息，考虑使用本地部署的开源模型（如Llama 3）而非云端API"
  ]
}
\`\`\`

---

## 案例3：合理方案 - 客服场景

**输入：**
- 业务场景：智能客服机器人，处理售后咨询和常见问题解答
- 模型：Claude 3 Sonnet（200B参数，多模态，200K上下文）
- 数据：6000条QA对话记录，已治理
- QPS需求：50，并发：100

**输出：**
\`\`\`json
{
  "score": 85,
  "summary": "技术方案整体合理：模型选择恰当，数据量充足，性能需求合理。建议优先使用RAG方案，根据效果决定是否微调。",
  "dimensions": {
    "modelTaskAlignment": {
      "score": 95,
      "status": "matched",
      "analysis": "客服场景需要强大的语义理解、多轮对话管理、上下文记忆和知识问答能力，Claude 3 Sonnet的200K上下文窗口和出色的文本理解生成能力与这些需求完美匹配。它能够理解用户的隐含意图、处理复杂的多轮对话、维护长对话上下文，并生成自然流畅的回复，这些都是客服机器人的核心能力。相比GPT-4，Claude 3在对话连贯性和安全性方面表现更优，特别适合客服这种需要高质量交互的场景。"
    },
    "llmNecessity": {
      "score": 90,
      "status": "necessary",
      "analysis": "客服场景的复杂性和开放性决定了必须使用大语言模型。用户咨询千变万化，既有标准FAQ，也有需要理解和推理的复杂问题，还要处理情绪化表达和模糊描述。小模型或传统NLU方案只能处理固定模式的问答，无法应对客服场景的灵活性和多样性。大模型的Few-Shot学习和In-Context Learning能力让它能够理解各种表达方式，生成个性化的回复，这是客服体验的关键。传统客服机器人往往被用户吐槽\"答非所问\"，正是因为缺乏这种理解和生成能力。"
    },
    "fineTuning": {
      "score": 75,
      "necessary": false,
      "dataAdequacy": "sufficient",
      "analysis": "6000条QA对话记录数据量充足，质量也已治理，理论上可以支持模型微调。但客服场景更推荐先使用RAG（检索增强生成）方案而非直接微调。RAG的优势在于：(1)不需要训练，部署更快 (2)可以动态更新知识库，新增FAQ无需重新训练 (3)可以追溯答案来源，提高可信度。将6000条QA向量化后存入向量数据库，配合Claude的生成能力，效果往往已经能满足80-90%的需求。只有在RAG召回率或答案质量不理想时，再考虑微调，这样可以大幅降低维护成本。"
    },
    "implementationRoadmap": {
      "score": 90,
      "feasible": true,
      "analysis": "技术方案非常可行，且实施路径清晰合理。客服机器人是LLM应用中技术成熟度最高的场景之一，有大量最佳实践可以参考。分阶段实施策略很明智：先用RAG快速上线基础FAQ问答，建立用户信任和收集反馈；再根据真实数据评估是否需要微调优化。这种渐进式策略既能快速见效（2-3周上线），又能控制风险和成本。每个阶段都有明确的里程碑和退出条件，符合敏捷开发理念。",
      "phases": {
        "shortTerm": [
          "第一阶段(2-3周)：实现基于RAG的FAQ问答系统，将6000条QA向量化后建立知识库，配合Claude生成答案",
          "配置相似度阈值（如0.7），低置信度问题自动转人工客服，保证服务质量",
          "建立基础监控：响应时间、召回率、用户满意度评分"
        ],
        "midTerm": [
          "第二阶段(1-2个月)：收集真实对话数据（至少2000条），分析RAG方案的不足",
          "如果召回率<80%或答案质量不理想，考虑用积累的数据进行LoRA微调",
          "优化多轮对话能力，增加上下文管理和意图识别模块"
        ]
      }
    },
    "performanceRequirements": {
      "score": 90,
      "reasonable": true,
      "analysis": "QPS 50、并发100对于中型客服场景来说是非常合理的负载需求。并发数是QPS的2倍，这个比例考虑到了大模型的推理时间（Claude 3 Sonnet平均2-3秒），能够在保证响应速度的同时支撑足够的用户量。按照这个负载，系统可以支持每天432万次对话（QPS 50 × 86400秒），足以应对大多数企业的客服需求。如果是7×24小时客服，QPS 50意味着理论上可以同时支持上千名用户在线咨询，这对于中型电商或SaaS企业已经完全够用。"
    },
    "costEfficiency": {
      "score": 85,
      "level": "reasonable",
      "analysis": "Claude 3 Sonnet的选型体现了很好的成本意识。它的成本约为Claude 3 Opus的1/5，但能力对于客服场景来说完全够用，相比Opus在对话质量上的差距很小，却能大幅降低成本。按QPS 50计算，每天约43.2万次API调用，以Claude 3 Sonnet的定价（约$0.003/1K tokens输入，$0.015/1K tokens输出），月成本在数千到万元级别，对于能够替代人工客服的价值来说，这个ROI是非常可观的。一个人工客服的月成本通常在5000-8000元，而AI客服可以7×24小时工作，处理量是人工的数十倍，因此投入产出比很高。"
    }
  },
  "criticalIssues": [],
  "warnings": [],
  "recommendations": [
    "优先实现RAG方案：将6000条QA向量化构建知识库，使用语义检索+Claude生成答案",
    "RAG方案的优势：无需微调、易于更新QA库、成本更低",
    "设置置信度阈值，不确定的问题转人工处理，保证服务质量",
    "收集上线后的真实对话数据，持续扩充QA库",
    "如果3个月后RAG效果不理想，再考虑用积累的数据进行微调"
  ]
}
\`\`\`

---

## 案例4：复杂场景分阶段实施 - 医疗领域

**输入：**
- 业务场景：医疗问诊助手，包括症状理解、疾病知识问答、用药建议、检查项目推荐
- 模型：GPT-4（1.7T参数，多模态，128K上下文）
- 数据：3000条医患对话记录，已标注
- QPS需求：30，并发：60

**输出：**
\`\`\`json
{
  "score": 55,
  "summary": "医疗场景具有特殊性，部分功能可实施但需谨慎。症状理解和知识问答可以做，但用药建议和诊断不建议AI直接给出。数据量偏少，需扩充。",
  "dimensions": {
    "modelTaskAlignment": {
      "score": 80,
      "status": "matched",
      "analysis": "医疗问诊助手需要理解复杂的医学术语、患者症状描述（往往不专业且模糊）、进行医学知识推理，GPT-4的强大语言理解和推理能力与这些需求高度匹配。特别是在理解患者的口语化症状描述、关联多个症状进行初步分析、解释医学概念等方面，GPT-4的表现优秀。128K的上下文窗口也足以承载完整的病历和多轮对话历史。但需要明确的是，AI不能替代医生进行诊断，只能作为辅助工具，这个定位必须清晰。"
    },
    "llmNecessity": {
      "score": 85,
      "status": "necessary",
      "analysis": "医疗场景的复杂性和专业性决定了必须使用大语言模型。患者的症状描述千差万别，同一个疾病可能有完全不同的表达方式，需要强大的语言理解能力。医学知识推理（如症状关联、疾病鉴别）需要在海量医学知识中进行检索和推理，小模型难以胜任。此外，医学解释需要将专业术语转化为患者能理解的语言，这也是大模型的强项。传统的规则引擎或决策树模型虽然在某些诊断场景下准确率高，但缺乏灵活性和解释能力，无法应对医疗场景的多样性。"
    },
    "fineTuning": {
      "score": 45,
      "necessary": true,
      "dataAdequacy": "insufficient",
      "analysis": "医疗领域的专业性和复杂性决定了必须进行微调，通用模型虽然有基础医学知识，但在特定医疗机构的诊疗规范、常见病种、用药习惯等方面缺乏针对性。然而，3000条医患对话记录对于医疗领域来说严重不足。医学涵盖数千种疾病、数万种症状组合，3000条数据无法覆盖常见疾病的变化，更不用说罕见病和并发症。建议至少扩充到8000-10000条，且必须由专业医生审核标注质量，确保诊断建议的准确性。数据不足导致的误诊风险在医疗场景中是不可接受的。"
    },
    "implementationRoadmap": {
      "score": 70,
      "feasible": true,
      "analysis": "医疗场景的特殊性要求必须严格区分不同功能的风险等级，分阶段实施是正确的策略。低风险功能（知识问答、症状收集）可以先上线，快速验证技术方案并建立用户信任。中风险功能（检查推荐、用药禁忌）需要更多数据积累和医生审核机制。高风险功能（诊断、用药剂量）则不应由AI直接给出，只能作为医生的参考。这种分层策略既能控制风险，又能逐步推进。但需要注意的是，即使是低风险功能，也必须配置完善的免责声明和人工审核机制，避免法律和伦理风险。",
      "phases": {
        "shortTerm": [
          "低风险功能(1-2个月)：基于权威医学知识库（如丁香医生、默沙东诊疗手册）的RAG实现疾病知识问答",
          "症状信息收集和结构化：帮助患者整理症状描述，生成结构化病历，但不给出诊断结论",
          "配置明显的免责声明：\"本系统仅供参考，不能替代医生诊断，请及时就医\""
        ],
        "midTerm": [
          "中风险功能(3-6个月)：检查项目推荐（基于症状和疾病知识库），但必须经医生审核后给出",
          "用药禁忌提示：基于药品说明书和患者过敏史，提示可能的用药禁忌，辅助医生决策",
          "数据扩充：收集真实使用数据，扩充训练集到8000-10000条"
        ],
        "notRecommended": [
          "不建议AI直接给患者：疾病诊断结论、具体用药建议（药物名称和剂量）- 医疗责任和伦理风险极高",
          "这些功能只能作为医生的辅助工具，显示在医生端界面，不能直接呈现给患者",
          "不要试图用AI替代医生，医疗决策的最终责任必须由医生承担"
        ]
      }
    },
    "performanceRequirements": {
      "score": 85,
      "reasonable": true,
      "analysis": "QPS 30、并发60对于医疗咨询场景是非常合理的中等负载需求。医疗对话往往比普通客服更长、更复杂，平均对话轮次可能达到5-10轮，每轮响应时间3-5秒，因此并发数是QPS的2倍是合理的。这个负载可以支持每天约260万次对话，对于单个医疗机构或在线问诊平台来说是足够的。医疗场景不追求极致的响应速度，患者可以接受3-5秒的等待时间以换取更准确的分析，因此性能需求设置是合理的。"
    },
    "costEfficiency": {
      "score": 75,
      "level": "reasonable",
      "analysis": "医疗场景选用GPT-4是合理的，因为准确性要求极高，任何错误都可能导致严重后果，这种场景下不能为了节省成本而降低模型能力。GPT-4在医学知识理解和推理方面的表现优于小模型，虽然成本较高（每月可能数万元），但相比医疗事故的潜在损失和人工问诊的成本，这个投入是值得的。一个医生的年薪通常在20-50万，而AI可以7×24小时提供初步筛查和知识问答，节省医生大量时间用于处理复杂病例，ROI是可观的。"
    },
    "domainConsiderations": {
      "score": 60,
      "applicable": true,
      "analysis": "医疗是高度敏感和强监管的领域，AI应用必须特别谨慎。法律风险：AI给出的错误建议可能导致误诊、延误治疗，造成医疗事故，机构和开发者都可能承担法律责任。伦理问题：患者生命健康高于一切，不能为了技术创新而冒险。因此必须配置多重保障措施：(1)强制的人工审核机制，所有涉及诊断、用药的建议必须医生审核 (2)明显的免责声明，多处提示用户\"仅供参考\" (3)完整记录所有交互，用于质量审查和责任追溯 (4)建立AI伦理委员会，定期评估系统的安全性和有效性。这些措施会增加实施成本和复杂度，但在医疗场景中是必不可少的。"
    }
  },
  "criticalIssues": [
    "数据量不足：3000条医患对话无法覆盖医疗领域复杂性"
  ],
  "warnings": [
    "医疗场景法律风险高，AI诊断和用药建议不能直接给患者",
    "需要明确的用户告知和免责声明"
  ],
  "recommendations": [
    "数据扩充：将医患对话数据扩充到8000-10000条，并请医生审核标注质量",
    "短期先实现低风险功能：疾病知识问答（基于权威医学知识库RAG）、症状信息收集",
    "配置强制的人工审核机制：所有涉及诊断、用药的建议必须医生审核后才能给出",
    "明确产品定位：AI辅助医生，而非替代医生",
    "用户界面需明确告知：本系统仅供参考，不能替代医生诊断",
    "所有交互完整记录，用于质量审查和责任追溯"
  ]
}
\`\`\`

---

## 案例5：数据量不足 - 金融风控

**输入：**
- 业务场景：信用卡欺诈检测，分析交易描述和用户行为判断异常
- 模型：Llama 3 8B（8B参数，纯文本，8K上下文，开源）
- 数据：800条标注的欺诈案例，已治理
- QPS需求：200，并发：400

**输出：**
\`\`\`json
{
  "score": 40,
  "summary": "方案存在严重问题：数据量严重不足，模型选择不当，性能需求与模型能力不匹配。金融风控场景风险高，需重新规划。",
  "dimensions": {
    "modelTaskAlignment": {
      "status": "partial",
      "analysis": "欺诈检测需要理解交易描述和行为模式，Llama 3 8B有一定文本理解能力，但金融场景需要更强的推理能力。"
    },
    "llmNecessity": {
      "status": "debatable",
      "analysis": "欺诈检测是分类任务，传统机器学习（XGBoost、随机森林）配合特征工程效果可能更好，且推理速度快、成本低。如果交易描述文本信息很重要，可以用BERT等小模型提取文本特征后结合传统模型。",
      "alternatives": "建议使用传统机器学习模型（XGBoost/LightGBM）+ BERT文本特征的组合方案，性能更高、可解释性更强。"
    },
    "fineTuning": {
      "necessary": true,
      "dataAdequacy": "insufficient",
      "analysis": "金融欺诈检测必须针对具体业务微调或训练。800条样本严重不足，欺诈模式多样，至少需要5000-10000条样本才能训练出可靠模型。且需要正负样本均衡。"
    },
    "implementationRoadmap": {
      "feasible": false,
      "analysis": "当前数据量和技术方案都不足以支撑金融风控场景的可靠性要求。",
      "phases": {
        "notRecommended": [
          "800条数据训练的模型不能直接用于生产环境，误判率会很高"
        ]
      }
    },
    "performanceRequirements": {
      "reasonable": false,
      "analysis": "QPS 200对于Llama 3 8B的推理速度是巨大挑战，需要大量GPU资源。而且并发400相对QPS 200过高（应该在400-600之间更合理）。金融场景需要毫秒级响应，大模型推理延迟可能不满足要求。"
    },
    "costEfficiency": {
      "level": "high",
      "analysis": "部署Llama 3 8B支持QPS 200需要大量GPU，成本很高。传统机器学习方案CPU即可，成本低90%以上。"
    },
    "domainConsiderations": {
      "applicable": true,
      "analysis": "金融风控是强监管领域，模型需要可解释性。大模型的黑盒特性可能不符合监管要求。传统机器学习模型可以提供特征重要性、决策路径，更适合金融场景。"
    }
  },
  "criticalIssues": [
    "数据量严重不足：800条样本无法训练可靠的欺诈检测模型",
    "性能需求不匹配：QPS 200对大模型推理是巨大挑战，延迟可能不满足要求",
    "技术选型不当：欺诈检测不一定需要大模型，传统ML可能更合适"
  ],
  "warnings": [
    "金融风控需要模型可解释性，大模型的黑盒特性可能不符合监管要求",
    "并发数相对QPS过高，可能配置有误"
  ],
  "recommendations": [
    "重新评估技术方案：考虑使用传统机器学习（XGBoost/LightGBM）+ 特征工程",
    "如果需要利用交易描述文本，使用BERT提取文本特征后输入传统模型",
    "数据积累：扩充欺诈样本到至少5000-10000条，保证正负样本均衡",
    "传统ML方案优势：推理速度快（毫秒级）、成本低、可解释性强、符合监管要求",
    "短期可先用规则引擎 + 少量ML模型建立基线系统，边运行边积累数据",
    "重新评估性能需求：确认QPS和并发数的真实需求"
  ]
}
\`\`\`

---

# 现在请评估以下项目

## 模型信息
${modelInfo}

## 用户需求
**业务场景：** ${req.businessScenario}

**训练数据：** ${req.businessData.volume}条${dataTypesStr}数据，${qualityStr}

**性能需求：** QPS ${req.performanceRequirements.qps}，并发 ${req.performanceRequirements.concurrency}

**硬件配置：** ${req.hardware} × ${req.cardCount}张

---

请严格参考以上案例的评估深度和风格，对当前项目进行全面评估。

## 关键要求

1. **评分准确性**：评分要准确反映方案质量
   - 0-30分：致命错误（如类型根本不匹配）
   - 40-59分：严重问题需要重大调整
   - 60-79分：有明显问题但可优化
   - 80-89分：整体合理有小改进空间
   - 90-100分：方案优秀

2. **分析连贯性**：每个维度的analysis字段用2-4句连贯的话深入分析（100-200字）
   - 不要写短句列表，要写完整段落
   - 要解释"为什么"，不仅说"是什么"
   - 要有逻辑推理过程

3. **实施路径**：如果业务场景复杂，必须在implementationRoadmap中给出清晰的分阶段路径
   - shortTerm: 低风险、快速见效的部分（1-2个月）
   - midTerm: 需要更多积累的部分（3-6个月）
   - notRecommended: 高风险不建议做的部分

4. **问题分层**：
   - criticalIssues: 只放阻断性、无法继续的问题
   - warnings: 需要注意但不阻断的问题

5. **建议可操作**：recommendations要具体可执行（3-5条）
   - 说明"做什么"+ "为什么这样做"
   - 不要泛泛而谈如"建议优化"

请直接输出JSON格式的评估结果，不要有任何其他文字。`
}
